
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Radon Example &#8212; Symbolic PyMC  documentation</title>
    <link rel="stylesheet" href="_static/semantic-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/semantic-ui@2.4.2/dist/semantic.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/default.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="_static/highlight.min.js"></script>
    <script src="_static/semantic.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Simplification Example" href="tensorflow-simplification-example.html" />
    <link rel="prev" title="Automatic Re-centering and Re-scaling" href="theano-radon-example.html" />
<script>hljs.initHighlightingOnLoad();</script>
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">



  </head><body>
<div class="ui vertical center aligned">

    <div class="ui container">
        <div class="ui large secondary pointing menu">
            <a class="item" href="/symbolic-pymc">
                Symbolic
                <img class="ui bottom aligned tiny image" src="https://cdn.rawgit.com/pymc-devs/pymc3/master/docs/logos/svg/PyMC3_banner.svg" />
            </a>
             <a href="index.html" class="item">Index</a> <a href="modules.html" class="item">API</a>
            
            <div class="right menu">
                <div class="item">
                    <form class="ui icon input" action="search.html" method="get">
                        <input type="text" placeholder="Search..." name="q" />
                        <i class="search link icon"></i>
                    </form>
                </div>
                <a class="item" href="https://github.com/pymc-devs/symbolic-pymc"><i class="github blue icon large"></i></a>
            </div>
        </div>
    </div>
    
</div>

<div class="ui container" role="main">
    

    <div class="ui vertical segment">
        
  <div class="section" id="radon-example">
<h1>Radon Example<a class="headerlink" href="#radon-example" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">Author</dt>
<dd class="field-odd"><p>Brandon T. Willard</p>
</dd>
<dt class="field-even">Date</dt>
<dd class="field-even"><p>2019-09-08</p>
</dd>
</dl>
</div></blockquote>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>In this example we’ll create a model “optimizer” that approximates the
re-centering and re-scaling commonly demonstrated on a hierarchical normal model
for the radon dataset.  This optimization is <strong>symbolic</strong> and effectively produces
another equivalent model with better sampling properties.</p>
<p>A similar example already exists in Theano and PyMC3; this example will operate
on TensorFlow (TF) graphs via PyMC4 and approximate the same optimization using
a very different approach targeted toward the log-likelihood graph.</p>
<p>To get started, we need to download the radon dataset.  We do this setup in
<span class="xref std std-ref">python-setup</span> and <span class="xref std std-ref">radon-data-download</span>, then we define the initial model
in <span class="xref std std-ref">pymc4-radon-model</span>.</p>
<div class="highlight-python notranslate" id="python-setup"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">pymc4</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="radon-data-download"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://github.com/pymc-devs/pymc3/raw/master/pymc3/examples/data/radon.csv&#39;</span><span class="p">)</span>

<span class="n">county_names</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">county</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">county_idx</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;county_code&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="pymc4-radon-model"><div class="highlight"><pre><span></span><span class="nd">@pm</span><span class="o">.</span><span class="n">model</span>
<span class="k">def</span> <span class="nf">hierarchical_model</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">county_idx</span><span class="p">):</span>
    <span class="c1"># Hyperpriors</span>
    <span class="n">mu_a</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;mu_alpha&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;sigma_alpha&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mu_b</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;mu_beta&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sigma_b</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;sigma_beta&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Intercept for each county, distributed around group mean mu_a</span>
    <span class="n">a</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu_a</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_a</span><span class="p">,</span> <span class="n">plate</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">county</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
    <span class="c1"># Intercept for each county, distributed around group mean mu_a</span>
    <span class="n">b</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu_b</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_b</span><span class="p">,</span> <span class="n">plate</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">county</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>

    <span class="c1"># Model error</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;eps&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Expected value</span>
    <span class="c1">#radon_est = a[county_idx] + b[county_idx] * data.floor.values</span>
    <span class="n">radon_est</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">county_idx</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">county_idx</span><span class="p">)</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">floor</span><span class="o">.</span><span class="n">values</span>

    <span class="c1"># Data likelihood</span>
    <span class="n">y_like</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_like&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">radon_est</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">log_radon</span><span class="p">)</span>


<span class="n">init_num_chains</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">hierarchical_model</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">county_idx</span><span class="p">)</span>
</pre></div>
</div>
<p>In <span class="xref std std-ref">pymc4-radon-model-sample</span>, we estimate the model using the sample
routine from <a class="reference external" href="https://github.com/pymc-devs/pymc4/blob/master/notebooks/radon_hierarchical.ipynb">PyMC4’s Radon example Notebook</a> (reproduced in
<span class="xref std std-ref">pymc4-sample-function</span>).  The same plots from the aforementioned notebook are
also reproduced here in <a class="reference internal" href="#fig-pymc4-radon-plot-energy">fig:pymc4-radon-plot-energy</a> and
<a class="reference internal" href="#fig-pymc4-radon-plot-trace">fig:pymc4-radon-plot-trace</a>.</p>
<div class="highlight-python notranslate" id="pymc4-sample-function"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">init_num_chains</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">burn_in</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
    <span class="n">init_num_chains</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="n">pm4_trace</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">inference</span><span class="o">.</span><span class="n">sampling</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">num_chains</span><span class="o">=</span><span class="n">init_num_chains</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">burn_in</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">xla</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">step_size_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pm4_trace</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">step_size_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">std</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">init_num_chains</span><span class="p">]</span> <span class="o">+</span> <span class="n">std</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">std</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="n">pm4_trace</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">inference</span><span class="o">.</span><span class="n">sampling</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">num_chains</span><span class="o">=</span><span class="n">init_num_chains</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span> <span class="o">+</span> <span class="mi">10</span><span class="o">*</span><span class="n">i</span><span class="p">,</span> <span class="n">burn_in</span><span class="o">=</span><span class="mi">10</span> <span class="o">+</span> <span class="mi">10</span><span class="o">*</span><span class="n">i</span><span class="p">,</span>
            <span class="n">step_size</span><span class="o">=</span><span class="n">step_size_</span><span class="p">,</span> <span class="n">xla</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">num_chains</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">step_size_</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pm4_trace</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">step_size_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">std</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">num_chains</span><span class="p">]</span><span class="o">+</span><span class="n">std</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">std</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

    <span class="n">pm4_trace</span><span class="p">,</span> <span class="n">sample_stat</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">inference</span><span class="o">.</span><span class="n">sampling</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">num_chains</span><span class="o">=</span><span class="n">num_chains</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">burn_in</span><span class="o">=</span><span class="n">burn_in</span><span class="p">,</span>
        <span class="n">step_size</span><span class="o">=</span><span class="n">step_size_</span><span class="p">,</span> <span class="n">xla</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">az_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">inference</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">trace_to_arviz</span><span class="p">(</span><span class="n">pm4_trace</span><span class="p">,</span> <span class="n">sample_stat</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">az_trace</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="pymc4-radon-model-sample"><div class="highlight"><pre><span></span><span class="n">az_trace</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="pymc4-radon-plot-setup"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">rcParams</span>


<span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">11.7</span><span class="p">,</span> <span class="mf">8.27</span><span class="p">)</span>

<span class="c1"># plt.rc(&#39;text&#39;, usetex=True)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;paper&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="pymc4-radon-plot-energy"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">plot_energy</span><span class="p">(</span><span class="n">az_trace</span><span class="p">)</span>
</pre></div>
</div>
<div class="align-center figure" id="id2">
<span id="fig-pymc4-radon-plot-energy"></span><a class="reference internal image-reference" href="_images/pymc4-radon-plot-energy.png"><img alt="_images/pymc4-radon-plot-energy.png" src="_images/pymc4-radon-plot-energy.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">Pre-transform MCMC energy</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<div class="align-center figure" id="id3">
<span id="fig-pymc4-radon-plot-trace"></span><a class="reference internal image-reference" href="_images/pymc4-radon-plot-trace.png"><img alt="_images/pymc4-radon-plot-trace.png" src="_images/pymc4-radon-plot-trace.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-number">Fig. 4 </span><span class="caption-text">Pre-transform MCMC trace</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="the-model-s-log-likelihood-graph">
<h2>The Model’s Log-likelihood Graph<a class="headerlink" href="#the-model-s-log-likelihood-graph" title="Permalink to this headline">¶</a></h2>
<p>In order to apply our optimization, we need to obtain a graph of the
log-likelihood function generated by the model in <span class="xref std std-ref">pymc4-radon-model</span>.
With the graph in-hand, we can perform the re-centering and re-scaling
transform–in log-space–and produce a new log-likelihood graph that improves
sampling.</p>
<p>This exercise introduces the TensorFlow function-graph backed by the class
<code class="docutils literal notranslate"><span class="pre">tensorflow.python.framework.func_graph.FuncGraph</span></code>.
<code class="docutils literal notranslate"><span class="pre">FuncGraph</span></code> is a subclass of the regular
<code class="docutils literal notranslate"><span class="pre">Graph</span></code> objects upon which
<code class="docutils literal notranslate"><span class="pre">symbolic-pymc</span></code> indirectly operates.  Just like
Theano’s
<code class="docutils literal notranslate"><span class="pre">FunctionGraph</span></code>s, <code class="docutils literal notranslate"><span class="pre">FuncGraph</span></code>simply specializes a generic graph by specifying which constituent tensors are
considered inputs and outputs.</p>
<p>In <span class="xref std std-ref">logp-func</span>, we use PyMC4’s internal mechanisms to build the
log-likelihood function for our model and a corresponding list of initial values
for the parameters.</p>
<div class="highlight-python notranslate" id="logp-func"><div class="highlight"><pre><span></span><span class="n">state</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">observed</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">logpfn</span><span class="p">,</span> <span class="n">init</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">inference</span><span class="o">.</span><span class="n">sampling</span><span class="o">.</span><span class="n">build_logp_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                                                         <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span>
                                                         <span class="n">observed</span><span class="o">=</span><span class="n">observed</span><span class="p">)</span>
</pre></div>
</div>
<p>From here we need <code class="docutils literal notranslate"><span class="pre">FuncGraph</span></code>s for each input
to <code class="docutils literal notranslate"><span class="pre">logpfn</span></code>.  Since <code class="docutils literal notranslate"><span class="pre">logpfn</span></code> is
a <code class="docutils literal notranslate"><span class="pre">tensorflow.python.eager.def_function.Function</span></code>instance, every time it’s called with a specific tensor it may create a new
function-object with its own <code class="docutils literal notranslate"><span class="pre">FuncGraph</span></code>.  In other
words, it dynamically generates function objects based on the inputs it’s given.</p>
<p>This specialization process can be performed manually
using <code class="docutils literal notranslate"><span class="pre">logpfn.get_concrete_function(*args)</span></code>, which
necessarily produces
a <code class="docutils literal notranslate"><span class="pre">tensorflow.python.eager.function.ConcreteFunction</span></code>with the desired <code class="docutils literal notranslate"><span class="pre">FuncGraph</span></code>.
<span class="xref std std-ref">fgraph-specializations</span> creates and extracts these two objects.</p>
<div class="highlight-python notranslate" id="fgraph-specializations"><div class="highlight"><pre><span></span><span class="n">logpfn_cf</span> <span class="o">=</span> <span class="n">logpfn</span><span class="o">.</span><span class="n">get_concrete_function</span><span class="p">(</span><span class="o">*</span><span class="n">init</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">logpfn_fg</span> <span class="o">=</span> <span class="n">logpfn_cf</span><span class="o">.</span><span class="n">graph</span>
</pre></div>
</div>
<p>The outputs are now available in graph form
as <code class="docutils literal notranslate"><span class="pre">logpfn_fg.outputs</span></code>.</p>
</div>
<div class="section" id="the-log-space-transform">
<h2>The Log-space Transform<a class="headerlink" href="#the-log-space-transform" title="Permalink to this headline">¶</a></h2>
<p>Consider the following two equivalent hierarchical models,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation}
  \begin{gathered}
    Y = X + \epsilon, \quad
    \epsilon \sim \operatorname{N}\left(0, \sigma^2\right)
    \\
    X \sim \operatorname{N}\left(\mu, \tau^2\right)
  \end{gathered}
\label{eq:model-1}
\end{equation}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation}
  \begin{gathered}
    Y = \mu + \tau \cdot \tilde{X} + \epsilon, \quad
    \epsilon \sim \operatorname{N}\left(0, \sigma^2\right)
    \\
    \tilde{X} \sim \operatorname{N}\left(0, 1\right)
  \;.
  \end{gathered}
\label{eq:model-2}
\end{equation}\end{split}\]</div>
<p>Models <a class="reference external" href="eq:model-1">eq:model-1</a> and <a class="reference external" href="eq:model-2">eq:model-2</a> are represented in (log) measure space,
respectively, as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
    \log p(Y, X) &amp;= \log P(Y\mid X) + \log P(X)
    \nonumber
    \\
    &amp;= C - \frac{1}{2} \left(\frac{y}{\sigma} - \frac{x}{\sigma}\right)^2 -
       \frac{1}{2} \left(\frac{x}{\tau} - \frac{\mu}{\tau}\right)^2
    \label{eq:log-model-1}
    \\
    &amp;= \tilde{C} - \frac{1}{2} \left(\frac{y}{\sigma} - \frac{\mu - \tau \cdot \tilde{x}}{\sigma}\right)^2 - \frac{1}{2} \tilde{x}^2
  \label{eq:log-model-2}
  \;.
\end{align}\end{split}\]</div>
<p>Via term rewriting, Equation <a class="reference external" href="eq:log-model-2">eq:log-model-2</a> is produced–in part–by
applying the replacement rule <span class="math notranslate nohighlight">\(x \to \mu + \tau \cdot \tilde{x}\)</span> to Equation
<a class="reference external" href="eq:log-model-1">eq:log-model-1</a>, i.e.</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
\tilde{C} - \frac{1}{2} \left(\frac{y}{\sigma} - \frac{\mu + \tau \cdot \tilde{x}}{\sigma}\right)^2 -
  \frac{1}{2} \left(\frac{\mu + \tau \cdot \tilde{x}}{\tau} - \frac{\mu}{\tau}\right)^2
\;.
\end{align*}\]</div>
<p>For consistency, the transform must also be applied to the <span class="math notranslate nohighlight">\(dx\)</span> term
where/when-ever it is considered.</p>
<p>After a few algebraic simplifications, one obtains the exact form of Equation
<a class="reference external" href="eq:log-model-2">eq:log-model-2</a>.</p>
</div>
<div class="section" id="creating-the-minikanren-goals">
<h2>Creating the miniKanren Goals<a class="headerlink" href="#creating-the-minikanren-goals" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">symbolic-pymc</span></code> is designed to use miniKanren as
a means of specifying mathematical relations.  The degree to which an
implementation of a mathematical relation upholds its known characteristics
is–of course–always up to the developer.  For the needs of PPLs like PyMC4,
we can’t reasonably expect–or provide–capabilities at the level of automatic
theorem proving or every relevant state-of-the-art symbolic math routine.</p>
<p>Even so, we <strong>do</strong> expect that some capabilities from within those more advanced areas
of symbolic computing will eventually be required–or necessary–and we want to build on a
foundation that allows them to be integrated and/or simply expressed.  We believe that
miniKanren is a great foundation for such work due to the core concepts it shares with
symbolic computation, as well as its immense flexibility.
It also maintains an elegant simplicity and is amenable to developer
intervention at nearly all levels–often without the need for low- or
DSL-level rewrites.</p>
<p>User-level development in miniKanren occurs within its DSL, which is a succinct
relational/logic programming paradigm that–in our case–is entirely written in
Python.  This DSL provides primitive <strong>goals</strong> that can be composed and eventually
evaluated by the <code class="docutils literal notranslate"><span class="pre">run</span></code> function.  We refer the reader
to any one of the many great introductions to miniKanren available at <a class="reference external" href="http://minikanren.org">http://minikanren.org</a>,
or, for the specific Python package used here: <a class="reference external" href="https://github.com/logpy/logpy/blob/master/doc/basic.md">this simple introduction</a>.</p>
<p>For the matter at hand, we need to create goals that implement the substitution
described above.  The first step is to understand the exact TF graphs involved,
and the best way to do that is to construct the relevant graph objects, observe
them directly, and build “patterns” that match their general forms.  Patterns
are built with <code class="docutils literal notranslate"><span class="pre">symbolic-pymc</span></code> meta objects obtained from
the <code class="docutils literal notranslate"><span class="pre">mt</span></code> helper “namespace”.  Wherever we want to leave
room for variation/ambiguity, we use a “logic variable” instead of an explicit
TF (meta) object.  Logic variables are created
with <code class="docutils literal notranslate"><span class="pre">var()</span></code> and can optionally be given a string “name”
argument that identifies them globally as a singleton-like object.</p>
<div class="section" id="inspecting-the-tf-graphs">
<h3>Inspecting the TF Graphs<a class="headerlink" href="#inspecting-the-tf-graphs" title="Permalink to this headline">¶</a></h3>
<p>In our case, the log-density returned by PyMC4–via the TensorFlow Probability
library (TFP)– uses <code class="docutils literal notranslate"><span class="pre">tf.math.squared_difference</span></code> to
construct the “squared error” term in the exponential of a normal distribution.
This term contains everything we need to construct the substitution as a pair
of TF graph objects.</p>
<p><span class="xref std std-ref">tfp-normal-log-lik-graph</span> shows the graph produced by a normal
distribution in TFP.</p>
<div class="highlight-python notranslate" id="tfp-normal-log-lik-graph"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.eager.context</span> <span class="kn">import</span> <span class="n">graph_mode</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework.ops</span> <span class="kn">import</span> <span class="n">disable_tensor_equality</span>

<span class="kn">from</span> <span class="nn">symbolic_pymc.tensorflow.printing</span> <span class="kn">import</span> <span class="n">tf_dprint</span>


<span class="n">disable_tensor_equality</span><span class="p">()</span>

<span class="k">with</span> <span class="n">graph_mode</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">test_graph</span><span class="p">:</span>
    <span class="n">mu_tf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span>
                                     <span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">]))</span>
    <span class="n">tau_tf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;tau&#39;</span><span class="p">,</span>
                                      <span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">]))</span>

    <span class="n">normal_tfp</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">normal</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu_tf</span><span class="p">,</span> <span class="n">tau_tf</span><span class="p">)</span>

    <span class="n">value_tf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">,</span>
                                        <span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">]))</span>

    <span class="n">normal_log_lik</span> <span class="o">=</span> <span class="n">normal_tfp</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">value_tf</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="tfp-normal-log-lik-graph-print"><div class="highlight"><pre><span></span><span class="n">tf_dprint</span><span class="p">(</span><span class="n">normal_log_lik</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Tensor(Sub):0,      dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/sub:0&quot;
|  Tensor(Mul):0,   dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/mul:0&quot;
|  |  Tensor(Const):0,      dtype=float32,  shape=[],       &quot;Normal_1/log_prob/mul/x:0&quot;
|  |  |  -0.5
|  |  Tensor(SquaredDifference):0,  dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/SquaredDifference:0&quot;
|  |  |  Tensor(RealDiv):0, dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/truediv:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[None],   &quot;value:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  |  |  Tensor(RealDiv):0, dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/truediv_1:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[None],   &quot;mu:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  Tensor(AddV2):0, dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/add:0&quot;
|  |  Tensor(Const):0,      dtype=float32,  shape=[],       &quot;Normal_1/log_prob/add/x:0&quot;
|  |  |  0.9189385
|  |  Tensor(Log):0,        dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/Log:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[None],   &quot;tau:0&quot;
</pre></div>
</div>
<p>Instead of looking for the entire log-likelihood graph for a distribution, we
can focus on only the <code class="docutils literal notranslate"><span class="pre">SquaredDifference</span></code> operators,
since they contain all the relevant terms for our transformation.</p>
<p>More specifically, if we can identify “chains” of such terms,
i.e.  <code class="docutils literal notranslate"><span class="pre">SquaredDifference(y,</span> <span class="pre">x)</span></code>and <code class="docutils literal notranslate"><span class="pre">SquaredDifference(x,</span> <span class="pre">mu)</span></code>, then we might be able to
assume that the corresponding subgraph was formed from such a hierarchical
normal model.</p>
<p><span class="xref std std-ref">show-squared-diff-terms</span> shows the <code class="docutils literal notranslate"><span class="pre">SquaredDifference</span></code>sub-graphs in the log-likelihood graph for our radon model.  It demonstrates two
instances of said <code class="docutils literal notranslate"><span class="pre">SquaredDifference</span></code>”chains”: they involve tensors named <code class="docutils literal notranslate"><span class="pre">values_5</span></code> and <code class="docutils literal notranslate"><span class="pre">values_1</span></code>.</p>
<div class="highlight-python notranslate" id="show-squared-diff-terms"><div class="highlight"><pre><span></span><span class="n">square_diff_outs</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">logpfn_fg</span><span class="o">.</span><span class="n">get_operations</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">o</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;SquaredDifference&#39;</span> <span class="ow">or</span> <span class="n">o</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;Gather&#39;</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">square_diff_outs</span><span class="p">:</span>
    <span class="n">tf_dprint</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Tensor(GatherV2):0, dtype=float32,  shape=[919],    &quot;GatherV2:0&quot;
|  Tensor(Placeholder):0,   dtype=float32,  shape=[85],     &quot;values_1:0&quot;
|  Tensor(Const):0, dtype=int32,    shape=[919],    &quot;GatherV2/indices:0&quot;
|  |  [ 0  0  0 ... 83 84 84]
|  Tensor(Const):0, dtype=int32,    shape=[],       &quot;GatherV2/axis:0&quot;
|  |  0
Tensor(GatherV2):0, dtype=float32,  shape=[919],    &quot;GatherV2_1:0&quot;
|  Tensor(Placeholder):0,   dtype=float32,  shape=[85],     &quot;values_3:0&quot;
|  Tensor(Const):0, dtype=int32,    shape=[919],    &quot;GatherV2_1/indices:0&quot;
|  |  [ 0  0  0 ... 83 84 84]
|  Tensor(Const):0, dtype=int32,    shape=[],       &quot;GatherV2_1/axis:0&quot;
|  |  0
Tensor(SquaredDifference):0,        dtype=float32,  shape=[],       &quot;Normal_5/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,       dtype=float32,  shape=[],       &quot;Normal_5/log_prob/truediv:0&quot;
|  |  Tensor(Placeholder):0,        dtype=float32,  shape=[],       &quot;values_0:0&quot;
|  |  Tensor(Const):0,      dtype=float32,  shape=[],       &quot;Normal/scale:0&quot;
|  |  |  1.
|  Tensor(RealDiv):0,       dtype=float32,  shape=[],       &quot;Normal_5/log_prob/truediv_1:0&quot;
|  |  Tensor(Const):0,      dtype=float32,  shape=[],       &quot;Normal/loc:0&quot;
|  |  |  0.
|  |  Tensor(Const):0,      dtype=float32,  shape=[],       &quot;Normal/scale:0&quot;
|  |  |  1.
Tensor(SquaredDifference):0,        dtype=float32,  shape=[],       &quot;Normal_1_1/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,       dtype=float32,  shape=[],       &quot;Normal_1_1/log_prob/truediv:0&quot;
|  |  Tensor(Placeholder):0,        dtype=float32,  shape=[],       &quot;values_6:0&quot;
|  |  Tensor(Const):0,      dtype=float32,  shape=[],       &quot;Normal_1/scale:0&quot;
|  |  |  1.
|  Tensor(RealDiv):0,       dtype=float32,  shape=[],       &quot;Normal_1_1/log_prob/truediv_1:0&quot;
|  |  Tensor(Const):0,      dtype=float32,  shape=[],       &quot;Normal_1/loc:0&quot;
|  |  |  0.
|  |  Tensor(Const):0,      dtype=float32,  shape=[],       &quot;Normal_1/scale:0&quot;
|  |  |  1.
Tensor(SquaredDifference):0,        dtype=float32,  shape=[85],     &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,       dtype=float32,  shape=[85],     &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv:0&quot;
|  |  Tensor(Transpose):0,  dtype=float32,  shape=[85],     &quot;SampleNormal_2_1/log_prob/transpose:0&quot;
|  |  |  Tensor(Reshape):0, dtype=float32,  shape=[85],     &quot;SampleNormal_2_1/log_prob/Reshape:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[85],     &quot;values_1:0&quot;
|  |  |  |  Tensor(Const):0,        dtype=int32,    shape=[1],      &quot;SampleNormal_2_1/log_prob/Reshape/shape:0&quot;
|  |  |  |  |  [85]
|  |  |  Tensor(Const):0,   dtype=int32,    shape=[1],      &quot;SampleNormal_2_1/log_prob/transpose/perm:0&quot;
|  |  |  |  [0]
|  |  Tensor(Exp):0,        dtype=float32,  shape=[],       &quot;exp_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[],       &quot;values_5:0&quot;
|  Tensor(RealDiv):0,       dtype=float32,  shape=[],       &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv_1:0&quot;
|  |  Tensor(Placeholder):0,        dtype=float32,  shape=[],       &quot;values_0:0&quot;
|  |  Tensor(Exp):0,        dtype=float32,  shape=[],       &quot;exp_1/forward/Exp:0&quot;
|  |  |  ...
Tensor(SquaredDifference):0,        dtype=float32,  shape=[85],     &quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,       dtype=float32,  shape=[85],     &quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv:0&quot;
|  |  Tensor(Transpose):0,  dtype=float32,  shape=[85],     &quot;SampleNormal_3_1/log_prob/transpose:0&quot;
|  |  |  Tensor(Reshape):0, dtype=float32,  shape=[85],     &quot;SampleNormal_3_1/log_prob/Reshape:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[85],     &quot;values_3:0&quot;
|  |  |  |  Tensor(Const):0,        dtype=int32,    shape=[1],      &quot;SampleNormal_3_1/log_prob/Reshape/shape:0&quot;
|  |  |  |  |  [85]
|  |  |  Tensor(Const):0,   dtype=int32,    shape=[1],      &quot;SampleNormal_3_1/log_prob/transpose/perm:0&quot;
|  |  |  |  [0]
|  |  Tensor(Exp):0,        dtype=float32,  shape=[],       &quot;exp_2_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[],       &quot;values_2:0&quot;
|  Tensor(RealDiv):0,       dtype=float32,  shape=[],       &quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv_1:0&quot;
|  |  Tensor(Placeholder):0,        dtype=float32,  shape=[],       &quot;values_6:0&quot;
|  |  Tensor(Exp):0,        dtype=float32,  shape=[],       &quot;exp_2_1/forward/Exp:0&quot;
|  |  |  ...
Tensor(SquaredDifference):0,        dtype=float32,  shape=[919],    &quot;Normal_4_1/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,       dtype=float32,  shape=[919],    &quot;Normal_4_1/log_prob/truediv:0&quot;
|  |  Tensor(Const):0,      dtype=float32,  shape=[919],    &quot;Normal_4_1/log_prob/value:0&quot;
|  |  |  [0.8329091 0.8329091 1.0986123 ... 1.6292405 1.3350011 1.0986123]
|  |  Tensor(Exp):0,        dtype=float32,  shape=[],       &quot;exp_3_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[],       &quot;values_4:0&quot;
|  Tensor(RealDiv):0,       dtype=float32,  shape=[919],    &quot;Normal_4_1/log_prob/truediv_1:0&quot;
|  |  Tensor(AddV2):0,      dtype=float32,  shape=[919],    &quot;add:0&quot;
|  |  |  Tensor(GatherV2):0,        dtype=float32,  shape=[919],    &quot;GatherV2:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[85],     &quot;values_1:0&quot;
|  |  |  |  Tensor(Const):0,        dtype=int32,    shape=[919],    &quot;GatherV2/indices:0&quot;
|  |  |  |  |  [ 0  0  0 ... 83 84 84]
|  |  |  |  Tensor(Const):0,        dtype=int32,    shape=[],       &quot;GatherV2/axis:0&quot;
|  |  |  |  |  0
|  |  |  Tensor(Mul):0,     dtype=float32,  shape=[919],    &quot;mul:0&quot;
|  |  |  |  Tensor(GatherV2):0,     dtype=float32,  shape=[919],    &quot;GatherV2_1:0&quot;
|  |  |  |  |  Tensor(Placeholder):0,       dtype=float32,  shape=[85],     &quot;values_3:0&quot;
|  |  |  |  |  Tensor(Const):0,     dtype=int32,    shape=[919],    &quot;GatherV2_1/indices:0&quot;
|  |  |  |  |  |  [ 0  0  0 ... 83 84 84]
|  |  |  |  |  Tensor(Const):0,     dtype=int32,    shape=[],       &quot;GatherV2_1/axis:0&quot;
|  |  |  |  |  |  0
|  |  |  |  Tensor(Const):0,        dtype=float32,  shape=[919],    &quot;mul/y:0&quot;
|  |  |  |  |  [1. 0. 0. ... 0. 0. 0.]
|  |  Tensor(Exp):0,        dtype=float32,  shape=[],       &quot;exp_3_1/forward/Exp:0&quot;
|  |  |  ...
</pre></div>
</div>
<p>The names in the TFP graph are not based on the PyMC4 model objects, so, to make
the graph output slightly more interpretable,
<span class="xref std std-ref">model-names-to-tfp-names</span> attempts to re-associate the TF and PyMC4 object names.</p>
<div class="highlight-python notranslate" id="model-names-to-tfp-names"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>

<span class="n">tfp_names_to_pymc</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">logpfn_cf</span><span class="o">.</span><span class="n">structured_input_signature</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">init</span><span class="o">.</span><span class="n">keys</span><span class="p">())}</span>
<span class="n">pymc_names_to_tfp</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tfp_names_to_pymc</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="n">alpha_tf</span> <span class="o">=</span> <span class="n">logpfn_fg</span><span class="o">.</span><span class="n">get_operation_by_name</span><span class="p">(</span><span class="n">pymc_names_to_tfp</span><span class="p">[</span><span class="s1">&#39;hierarchical_model/alpha&#39;</span><span class="p">])</span>
<span class="n">beta_tf</span> <span class="o">=</span> <span class="n">logpfn_fg</span><span class="o">.</span><span class="n">get_operation_by_name</span><span class="p">(</span><span class="n">pymc_names_to_tfp</span><span class="p">[</span><span class="s1">&#39;hierarchical_model/beta&#39;</span><span class="p">])</span>

<span class="n">pprint</span><span class="p">(</span><span class="n">tfp_names_to_pymc</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;values_0&#39;</span><span class="p">:</span> <span class="s1">&#39;hierarchical_model/mu_alpha&#39;</span><span class="p">,</span>
 <span class="s1">&#39;values_1&#39;</span><span class="p">:</span> <span class="s1">&#39;hierarchical_model/alpha&#39;</span><span class="p">,</span>
 <span class="s1">&#39;values_2&#39;</span><span class="p">:</span> <span class="s1">&#39;hierarchical_model/__log_sigma_beta&#39;</span><span class="p">,</span>
 <span class="s1">&#39;values_3&#39;</span><span class="p">:</span> <span class="s1">&#39;hierarchical_model/beta&#39;</span><span class="p">,</span>
 <span class="s1">&#39;values_4&#39;</span><span class="p">:</span> <span class="s1">&#39;hierarchical_model/__log_eps&#39;</span><span class="p">,</span>
 <span class="s1">&#39;values_5&#39;</span><span class="p">:</span> <span class="s1">&#39;hierarchical_model/__log_sigma_alpha&#39;</span><span class="p">,</span>
 <span class="s1">&#39;values_6&#39;</span><span class="p">:</span> <span class="s1">&#39;hierarchical_model/mu_beta&#39;</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="graph-normalization">
<h3>Graph Normalization<a class="headerlink" href="#graph-normalization" title="Permalink to this headline">¶</a></h3>
<p>In general, we don’t want our “patterns” to be “brittle”, e.g. rely on
explicit–yet variable–term orderings in commutative operators (e.g. a pattern
that exclusively targets <code class="docutils literal notranslate"><span class="pre">mt.add(x_lv,</span> <span class="pre">y_lv)</span></code> and won’t
match the equivalent <code class="docutils literal notranslate"><span class="pre">mt.add(y_lv,</span> <span class="pre">x_lv)</span></code>).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">grappler</span></code> library in TensorFlow provides a subset of
graph pruning/optimization steps.  Ideally, a library like <code class="docutils literal notranslate"><span class="pre">grappler</span></code>would provide full-fledged graph normalization/canonicalization upon which we could
base the subgraphs used in our relations.</p>
<p>While <code class="docutils literal notranslate"><span class="pre">grappler</span></code> does appear to provide some minimal
algebraic normalizations, the extent to which these are performed and their
breadth of relevant operator coverage isn’t clear; however, the normalizations
that it does provide are worth using, so we’ll make use of them throughout.</p>
<p><span class="xref std std-ref">grappler-normalize-function</span> provides a simple means of
applying <code class="docutils literal notranslate"><span class="pre">grappler</span></code>.</p>
<div class="highlight-python notranslate" id="grappler-normalize-function"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.core.protobuf</span> <span class="kn">import</span> <span class="n">config_pb2</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">importer</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">meta_graph</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.grappler</span> <span class="kn">import</span> <span class="n">cluster</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.grappler</span> <span class="kn">import</span> <span class="n">tf_optimizer</span>


<span class="k">try</span><span class="p">:</span>
    <span class="n">gcluster</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">Cluster</span><span class="p">()</span>
<span class="k">except</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">UnavailableError</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">config_pb2</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">normalize_tf_graph</span><span class="p">(</span><span class="n">graph_output</span><span class="p">,</span> <span class="n">new_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Use grappler to normalize a graph.</span>

<span class="sd">    Arguments</span>
<span class="sd">    =========</span>
<span class="sd">    graph_output: Tensor</span>
<span class="sd">      A tensor we want to consider as &quot;output&quot; of a FuncGraph.</span>

<span class="sd">    Returns</span>
<span class="sd">    =======</span>
<span class="sd">    The simplified graph.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train_op</span> <span class="o">=</span> <span class="n">graph_output</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_collection_ref</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">TRAIN_OP</span><span class="p">)</span>
    <span class="n">train_op</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">train_op</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">graph_output</span><span class="p">])</span>

    <span class="n">metagraph</span> <span class="o">=</span> <span class="n">meta_graph</span><span class="o">.</span><span class="n">create_meta_graph_def</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">graph_output</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>

    <span class="n">optimized_graphdef</span> <span class="o">=</span> <span class="n">tf_optimizer</span><span class="o">.</span><span class="n">OptimizeGraph</span><span class="p">(</span>
        <span class="n">config</span><span class="p">,</span> <span class="n">metagraph</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">cluster</span><span class="o">=</span><span class="n">gcluster</span><span class="p">)</span>

    <span class="n">output_name</span> <span class="o">=</span> <span class="n">graph_output</span><span class="o">.</span><span class="n">name</span>

    <span class="k">if</span> <span class="n">new_graph</span><span class="p">:</span>
        <span class="n">optimized_graph</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">optimized_graph</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">graph_output</span>

    <span class="k">with</span> <span class="n">optimized_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="n">importer</span><span class="o">.</span><span class="n">import_graph_def</span><span class="p">(</span><span class="n">optimized_graphdef</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="n">opt_graph_output</span> <span class="o">=</span> <span class="n">optimized_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="n">output_name</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">opt_graph_output</span>
</pre></div>
</div>
<p>In <span class="xref std std-ref">grappler-normalize-function</span> we
run <code class="docutils literal notranslate"><span class="pre">grappler</span></code> on the log-likelihood graph for a normal
random variable from <span class="xref std std-ref">tfp-normal-log-lik-graph</span>.</p>
<div class="highlight-python notranslate" id="grappler-normalize-test-graph"><div class="highlight"><pre><span></span><span class="n">normal_log_lik_opt</span> <span class="o">=</span> <span class="n">normalize_tf_graph</span><span class="p">(</span><span class="n">normal_log_lik</span><span class="p">)</span>
</pre></div>
</div>
<p><span class="xref std std-ref">opt-graph-output-cmp</span> compares the computed outputs for the original and
normalized graphs–given identical inputs.</p>
<div class="highlight-python notranslate" id="opt-graph-output-cmp"><div class="highlight"><pre><span></span><span class="n">res_unopt</span> <span class="o">=</span> <span class="n">normal_log_lik</span><span class="o">.</span><span class="n">eval</span><span class="p">({</span><span class="s1">&#39;mu:0&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;tau:0&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;value:0&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">1</span><span class="p">]},</span>
                                 <span class="n">session</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">normal_log_lik</span><span class="o">.</span><span class="n">graph</span><span class="p">))</span>

<span class="n">res_opt</span> <span class="o">=</span> <span class="n">normal_log_lik_opt</span><span class="o">.</span><span class="n">eval</span><span class="p">({</span><span class="s1">&#39;mu:0&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;tau:0&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;value:0&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">1</span><span class="p">]},</span>
                                  <span class="n">session</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">normal_log_lik_opt</span><span class="o">.</span><span class="n">graph</span><span class="p">))</span>

<span class="c1"># They should be equal, naturally</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">res_unopt</span><span class="p">,</span> <span class="n">res_opt</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="p">[</span><span class="n">res_unopt</span><span class="p">,</span> <span class="n">res_opt</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">2.9189386</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">2.9189386</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)]</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="opt-graph-print"><div class="highlight"><pre><span></span><span class="n">tf_dprint</span><span class="p">(</span><span class="n">normal_log_lik_opt</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Tensor(Sub):0,      dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/sub:0&quot;
|  Tensor(Mul):0,   dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/mul:0&quot;
|  |  Tensor(SquaredDifference):0,  dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/SquaredDifference:0&quot;
|  |  |  Tensor(RealDiv):0, dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/truediv:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[None],   &quot;value:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  |  |  Tensor(RealDiv):0, dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/truediv_1:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[None],   &quot;mu:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  |  Tensor(Const):0,      dtype=float32,  shape=[],       &quot;Normal_1/log_prob/mul/x:0&quot;
|  |  |  -0.5
|  Tensor(AddV2):0, dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/add:0&quot;
|  |  Tensor(Log):0,        dtype=float32,  shape=[None],   &quot;Normal_1/log_prob/Log:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  |  Tensor(Const):0,      dtype=float32,  shape=[],       &quot;Normal_1/log_prob/add/x:0&quot;
|  |  |  0.9189385
</pre></div>
</div>
<p>From the output of <span class="xref std std-ref">opt-graph-print</span>, we can see
that <code class="docutils literal notranslate"><span class="pre">grappler</span></code> has performed some constant folding and
has reordered the inputs in <code class="docutils literal notranslate"><span class="pre">&quot;add_1_1&quot;</span></code>–among other
things.</p>
</div>
<div class="section" id="minikanren-transform-relations">
<h3>miniKanren Transform Relations<a class="headerlink" href="#minikanren-transform-relations" title="Permalink to this headline">¶</a></h3>
<p>In <span class="xref std std-ref">kanren-shift-squaredo-func</span> and <span class="xref std std-ref">tfp-normal-log-prob</span> we perform all
the necessary imports and create a few useful helper functions.</p>
<div class="highlight-python notranslate" id="kanren-shift-squaredo-func"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Sequence</span>

<span class="kn">from</span> <span class="nn">unification</span> <span class="kn">import</span> <span class="n">var</span><span class="p">,</span> <span class="n">reify</span><span class="p">,</span> <span class="n">unify</span>

<span class="kn">from</span> <span class="nn">kanren</span> <span class="kn">import</span> <span class="n">run</span><span class="p">,</span> <span class="n">eq</span><span class="p">,</span> <span class="n">lall</span><span class="p">,</span> <span class="n">conde</span>
<span class="kn">from</span> <span class="nn">kanren.goals</span> <span class="kn">import</span> <span class="n">not_equalo</span>
<span class="kn">from</span> <span class="nn">kanren.core</span> <span class="kn">import</span> <span class="n">goaleval</span>
<span class="kn">from</span> <span class="nn">kanren.graph</span> <span class="kn">import</span> <span class="n">reduceo</span><span class="p">,</span> <span class="n">walko</span><span class="p">,</span> <span class="n">applyo</span>

<span class="kn">from</span> <span class="nn">etuples</span> <span class="kn">import</span> <span class="n">etuple</span><span class="p">,</span> <span class="n">etuplize</span>
<span class="kn">from</span> <span class="nn">etuples.core</span> <span class="kn">import</span> <span class="n">ExpressionTuple</span>

<span class="kn">from</span> <span class="nn">symbolic_pymc.meta</span> <span class="kn">import</span> <span class="n">enable_lvar_defaults</span>
<span class="kn">from</span> <span class="nn">symbolic_pymc.tensorflow.meta</span> <span class="kn">import</span> <span class="n">mt</span>


<span class="k">def</span> <span class="nf">onceo</span><span class="p">(</span><span class="n">goal</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A non-relational operator that yields only the first result from a relation.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">onceo_goal</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
        <span class="k">nonlocal</span> <span class="n">goal</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">reify</span><span class="p">(</span><span class="n">goal</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="n">g_stream</span> <span class="o">=</span> <span class="n">goaleval</span><span class="p">(</span><span class="n">g</span><span class="p">)(</span><span class="n">s</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">g_stream</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">s</span>

    <span class="k">return</span> <span class="n">onceo_goal</span>


<span class="k">def</span> <span class="nf">eval_objo</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">shallow</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a goal that relates an ExpressionTuple to its evaluated result.</span>

<span class="sd">    It&#39;s not an `evalo`-like relation, because it won&#39;t generate</span>
<span class="sd">    `ExpressionTuple`s that evaluate to any value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">eval_objo_goal</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
        <span class="k">nonlocal</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">shallow</span>

        <span class="n">x_ref</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">,</span> <span class="n">shallow</span> <span class="o">=</span> <span class="n">reify</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">shallow</span><span class="p">),</span> <span class="n">s</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_ref</span><span class="p">,</span> <span class="n">ExpressionTuple</span><span class="p">):</span>
            <span class="n">x_ref</span> <span class="o">=</span> <span class="n">x_ref</span><span class="o">.</span><span class="n">eval_obj</span>
            <span class="k">yield from</span> <span class="n">eq</span><span class="p">(</span><span class="n">x_ref</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">)(</span><span class="n">s</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">y_ref</span> <span class="o">=</span> <span class="n">etuplize</span><span class="p">(</span><span class="n">y_ref</span><span class="p">,</span> <span class="n">shallow</span><span class="o">=</span><span class="n">shallow</span><span class="p">)</span>
                <span class="k">yield from</span> <span class="n">eq</span><span class="p">(</span><span class="n">x_ref</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">)(</span><span class="n">s</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="k">pass</span>

    <span class="k">return</span> <span class="n">eval_objo_goal</span>
</pre></div>
</div>
<p>The function <code class="docutils literal notranslate"><span class="pre">onceo</span></code> is a goal that provides a convenient way to
extract only the first result from a goal stream.  This is useful when one only needs
the first result from a fixed-point-producing goal like <code class="docutils literal notranslate"><span class="pre">walko</span></code> (and
or TF-specific <code class="docutils literal notranslate"><span class="pre">walko</span></code>), since the first result
from such goals is the fixed-point–in certain cases–and the rest is a stream of goals
producing all the possible paths leading up to that point.</p>
<div class="highlight-python notranslate" id="tfp-normal-log-prob"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mt_normal_log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a meta graph for canonicalized standard and non-standard TFP normal log-likelihoods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">loc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">log_unnormalized_mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">squareddifference</span><span class="p">(</span>
            <span class="n">mt</span><span class="o">.</span><span class="n">realdiv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span> <span class="k">if</span> <span class="n">scale</span> <span class="o">!=</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">mt</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">),</span> <span class="n">x</span><span class="p">),</span>
            <span class="n">mt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">))</span>
        <span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">log_unnormalized_mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">squareddifference</span><span class="p">(</span>
            <span class="n">mt</span><span class="o">.</span><span class="n">realdiv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span> <span class="k">if</span> <span class="n">scale</span> <span class="o">!=</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">mt</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">),</span> <span class="n">x</span><span class="p">),</span>
            <span class="n">mt</span><span class="o">.</span><span class="n">realdiv</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span> <span class="k">if</span> <span class="n">scale</span> <span class="o">!=</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">mt</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">),</span> <span class="n">loc</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>

    <span class="n">log_normalization_mt</span> <span class="o">=</span> <span class="n">mt</span><span class="p">((</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">scale</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">log_normalization_mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_normalization_mt</span>

    <span class="k">return</span> <span class="n">log_unnormalized_mt</span> <span class="o">-</span> <span class="n">log_normalization_mt</span>
</pre></div>
</div>
<p><span class="xref std std-ref">tfp-normal-log-prob</span> is a function that will produce a meta graph for the
normalized form of a TFP normal log-likelihood.</p>
<p>In <span class="xref std std-ref">shift-squared-subso</span>, we create the miniKanren goals that identify the
aforementioned normal log-likelihood “chains” and create the
re-centering/scaling substitutions.</p>
<div class="highlight-python notranslate" id="shift-squared-subso"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">kanren.assoccomm</span> <span class="kn">import</span> <span class="n">eq_comm</span>


<span class="k">def</span> <span class="nf">shift_squared_subso</span><span class="p">(</span><span class="n">in_graph</span><span class="p">,</span> <span class="n">out_graph</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Construct a goal that produces transforms for chains like (y + x)**2, (x + z)**2.&quot;&quot;&quot;</span>

    <span class="n">y_lv</span> <span class="o">=</span> <span class="n">var</span><span class="p">()</span>
    <span class="n">x_lv</span> <span class="o">=</span> <span class="n">var</span><span class="p">()</span>
    <span class="n">mu_x_lv</span> <span class="o">=</span> <span class="n">var</span><span class="p">()</span>
    <span class="n">scale_y_lv</span> <span class="o">=</span> <span class="n">var</span><span class="p">()</span>

    <span class="c1"># TFP (or PyMC4) applies a reshape to the log-likelihood values, so</span>
    <span class="c1"># we need to anticipate that.  If we wanted, we could consider this</span>
    <span class="c1"># detail as just another possibility (and not a requirement) by using a</span>
    <span class="c1"># `conde` goal.</span>
    <span class="n">y_rshp_lv</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_lv</span><span class="p">,</span> <span class="n">var</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="n">var</span><span class="p">())</span>
    <span class="n">y_loglik_lv</span> <span class="o">=</span> <span class="n">var</span><span class="p">()</span>

    <span class="c1"># Create a non-standard normal &quot;pattern&quot; graph for the &quot;Y&quot; term with all</span>
    <span class="c1"># the unnecessary details set to logic variables</span>
    <span class="k">with</span> <span class="n">enable_lvar_defaults</span><span class="p">(</span><span class="s1">&#39;names&#39;</span><span class="p">,</span> <span class="s1">&#39;node_attrs&#39;</span><span class="p">):</span>
        <span class="n">y_loglik_pat_lv</span> <span class="o">=</span> <span class="n">mt_normal_log_prob</span><span class="p">(</span><span class="n">y_rshp_lv</span><span class="p">,</span> <span class="n">x_lv</span><span class="p">,</span> <span class="n">scale_y_lv</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">y_loglik</span><span class="p">(</span><span class="n">in_g</span><span class="p">,</span> <span class="n">out_g</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">lall</span><span class="p">(</span><span class="n">eq_comm</span><span class="p">(</span><span class="n">y_loglik_pat_lv</span><span class="p">,</span> <span class="n">in_g</span><span class="p">),</span>
                    <span class="c1"># This logic variable captures the *actual* subgraph that</span>
                    <span class="c1"># matches our pattern; we can&#39;t assume our pattern *is* the</span>
                    <span class="c1"># same subgraph, since we&#39;re considering commutative</span>
                    <span class="c1"># operations (i.e. our pattern might not have the same</span>
                    <span class="c1"># argument order as the actual subgraph, so we can&#39;t use it</span>
                    <span class="c1"># to search-and-replace later on).</span>
                    <span class="n">eq</span><span class="p">(</span><span class="n">y_loglik_lv</span><span class="p">,</span> <span class="n">in_g</span><span class="p">))</span>

    <span class="c1"># We do the same for the &quot;X&quot; term, but we include the possibility that</span>
    <span class="c1"># &quot;X&quot; is both a standard and a non-standard normal.</span>
    <span class="k">with</span> <span class="n">enable_lvar_defaults</span><span class="p">(</span><span class="s1">&#39;names&#39;</span><span class="p">,</span> <span class="s1">&#39;node_attrs&#39;</span><span class="p">):</span>
        <span class="n">x_loglik_lv</span> <span class="o">=</span> <span class="n">mt_normal_log_prob</span><span class="p">(</span><span class="n">x_lv</span><span class="p">,</span> <span class="n">mu_x_lv</span><span class="p">,</span> <span class="n">var</span><span class="p">())</span>
        <span class="n">x_std_loglik_lv</span> <span class="o">=</span> <span class="n">mt_normal_log_prob</span><span class="p">(</span><span class="n">x_lv</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">x_loglik</span><span class="p">(</span><span class="n">in_g</span><span class="p">,</span> <span class="n">out_g</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">conde</span><span class="p">([</span><span class="n">eq_comm</span><span class="p">(</span><span class="n">in_g</span><span class="p">,</span> <span class="n">x_loglik_lv</span><span class="p">)],</span>
                     <span class="p">[</span><span class="n">eq_comm</span><span class="p">(</span><span class="n">in_g</span><span class="p">,</span> <span class="n">x_std_loglik_lv</span><span class="p">)])</span>

    <span class="c1"># This is the re-center/scaling: mu + scale * y</span>
    <span class="n">y_new_lv</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">addv2</span><span class="p">(</span><span class="n">x_lv</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">scale_y_lv</span><span class="p">,</span> <span class="n">y_lv</span><span class="p">))</span>

    <span class="c1"># We have to use a new variable here so that we avoid transforming</span>
    <span class="c1"># inside the transformed value.</span>
    <span class="n">y_temp_lv</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">Placeholder</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">y_new_loglik_lv</span> <span class="o">=</span> <span class="n">mt_normal_log_prob</span><span class="p">(</span><span class="n">y_temp_lv</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">trans_disto</span><span class="p">(</span><span class="n">in_g</span><span class="p">,</span> <span class="n">out_g</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">lall</span><span class="p">(</span><span class="n">eq</span><span class="p">(</span><span class="n">in_g</span><span class="p">,</span> <span class="n">y_loglik_lv</span><span class="p">),</span>
                    <span class="n">eq</span><span class="p">(</span><span class="n">out_g</span><span class="p">,</span> <span class="n">y_new_loglik_lv</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">trans_varo</span><span class="p">(</span><span class="n">in_g</span><span class="p">,</span> <span class="n">out_g</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">conde</span><span class="p">([</span><span class="n">eq</span><span class="p">(</span><span class="n">in_g</span><span class="p">,</span> <span class="n">y_lv</span><span class="p">),</span>
                      <span class="n">eq</span><span class="p">(</span><span class="n">out_g</span><span class="p">,</span> <span class="n">y_new_lv</span><span class="p">)],</span>
                     <span class="p">[</span><span class="n">eq</span><span class="p">(</span><span class="n">in_g</span><span class="p">,</span> <span class="n">y_temp_lv</span><span class="p">),</span>
                      <span class="n">eq</span><span class="p">(</span><span class="n">out_g</span><span class="p">,</span> <span class="n">y_rshp_lv</span><span class="p">)])</span>

    <span class="c1"># A logic variable that corresponds to a partially transformed output</span>
    <span class="c1"># graph.</span>
    <span class="n">loglik_replaced_et</span><span class="p">,</span> <span class="n">loglik_replaced_mt</span> <span class="o">=</span> <span class="n">var</span><span class="p">(),</span> <span class="n">var</span><span class="p">()</span>
    <span class="n">y_transed_graph_et</span> <span class="o">=</span> <span class="n">var</span><span class="p">()</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">lall</span><span class="p">(</span>
        <span class="c1"># The first (y - x/a)**2 (anywhere in the graph)</span>
        <span class="n">walko</span><span class="p">(</span><span class="n">y_loglik</span><span class="p">,</span> <span class="n">in_graph</span><span class="p">,</span> <span class="n">in_graph</span><span class="p">),</span>

        <span class="c1"># The corresponding (x/b - z)**2 (also anywhere else in the graph)</span>
        <span class="n">walko</span><span class="p">(</span><span class="n">x_loglik</span><span class="p">,</span> <span class="n">in_graph</span><span class="p">,</span> <span class="n">in_graph</span><span class="p">),</span>

        <span class="c1"># Not sure if we need this, but we definitely don&#39;t want X == Y</span>
        <span class="p">(</span><span class="n">not_equalo</span><span class="p">,</span> <span class="p">[</span><span class="n">y_lv</span><span class="p">,</span> <span class="n">x_lv</span><span class="p">],</span> <span class="kc">True</span><span class="p">),</span>

        <span class="c1"># Replace Y&#39;s log-likelihood subgraph with the standardized version</span>
        <span class="c1"># onceo(reduceo(partial(walko, trans_disto), in_graph, mid_graph)),</span>
        <span class="n">onceo</span><span class="p">(</span><span class="n">walko</span><span class="p">(</span><span class="n">trans_disto</span><span class="p">,</span> <span class="n">in_graph</span><span class="p">,</span> <span class="n">loglik_replaced_et</span><span class="p">)),</span>

        <span class="c1"># Evaluate the resulting expression tuples</span>
        <span class="n">eval_objo</span><span class="p">(</span><span class="n">loglik_replaced_et</span><span class="p">,</span> <span class="n">loglik_replaced_mt</span><span class="p">),</span>

        <span class="c1"># Replace any other references to Y with the transformed version and</span>
        <span class="c1"># any occurrences of our temporary Y variable.</span>
        <span class="n">conde</span><span class="p">([</span><span class="n">onceo</span><span class="p">(</span><span class="n">walko</span><span class="p">(</span><span class="n">trans_varo</span><span class="p">,</span> <span class="n">loglik_replaced_mt</span><span class="p">,</span> <span class="n">y_transed_graph_et</span><span class="p">)),</span>
               <span class="n">eval_objo</span><span class="p">(</span><span class="n">y_transed_graph_et</span><span class="p">,</span> <span class="n">out_graph</span><span class="p">)],</span>
              <span class="c1"># Y might only appear in its log-likelihood subgraph, so that no</span>
              <span class="c1"># transformations are necessary/possible.  We address that</span>
              <span class="c1"># possibility here.</span>
              <span class="p">[</span><span class="n">eq</span><span class="p">(</span><span class="n">loglik_replaced_mt</span><span class="p">,</span> <span class="n">out_graph</span><span class="p">)]),</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="shift-squared-terms"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">shift_squared_terms</span><span class="p">(</span><span class="n">in_obj</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Re-center/scale hierarchical normals.&quot;&quot;&quot;</span>

    <span class="c1"># Normalize and convert to a meta graph</span>
    <span class="n">normed_in_obj</span> <span class="o">=</span> <span class="n">normalize_tf_graph</span><span class="p">(</span><span class="n">in_obj</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">normed_in_obj</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>

        <span class="n">in_obj</span> <span class="o">=</span> <span class="n">mt</span><span class="p">(</span><span class="n">normed_in_obj</span><span class="p">)</span>
        <span class="n">out_graph_lv</span> <span class="o">=</span> <span class="n">var</span><span class="p">()</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_graph_lv</span><span class="p">,</span> <span class="n">reduceo</span><span class="p">(</span><span class="n">shift_squared_subso</span><span class="p">,</span> <span class="n">in_obj</span><span class="p">,</span> <span class="n">out_graph_lv</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">res</span><span class="p">:</span>

            <span class="k">def</span> <span class="nf">reify_res</span><span class="p">(</span><span class="n">graph_res</span><span class="p">):</span>
                <span class="sd">&quot;&quot;&quot;Reconstruct and/or reify meta object results.&quot;&quot;&quot;</span>
                <span class="n">from_etuple</span> <span class="o">=</span> <span class="n">graph_res</span><span class="o">.</span><span class="n">eval_obj</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">graph_res</span><span class="p">,</span> <span class="n">ExpressionTuple</span><span class="p">)</span> <span class="k">else</span> <span class="n">graph_res</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">from_etuple</span><span class="p">,</span> <span class="s1">&#39;reify&#39;</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">from_etuple</span><span class="o">.</span><span class="n">reify</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">from_etuple</span>

            <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">reify_res</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">res</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Pattern not found in graph.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">graph_res</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">normalize_tf_graph</span><span class="p">(</span><span class="n">graph_res</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Results could not be fully reified to a base object.&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="testing-the-new-goals">
<h4>Testing the new Goals<a class="headerlink" href="#testing-the-new-goals" title="Permalink to this headline">¶</a></h4>
<p>As a test, we will run our miniKanren relations on the log-likelihood graph for a
normal-normal hierarchical model in <span class="xref std std-ref">non-trivial-transform-test-graph</span>.</p>
<div class="highlight-python notranslate" id="non-trivial-transform-test-graph"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">graph_mode</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">demo_graph</span><span class="p">:</span>
    <span class="n">X_tfp</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">normal</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>

    <span class="n">x_tf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;value_x&#39;</span><span class="p">,</span>
                                    <span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">]))</span>

    <span class="n">tau_tf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;tau&#39;</span><span class="p">,</span>
                                      <span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">]))</span>

    <span class="n">Y_tfp</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">normal</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">x_tf</span><span class="p">,</span> <span class="n">tau_tf</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">)</span>

    <span class="n">y_tf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;value_y&#39;</span><span class="p">,</span>
                                    <span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">]))</span>

    <span class="n">y_T_reshaped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_tf</span><span class="p">,</span> <span class="p">[]))</span>

    <span class="c1"># This term should end up being replaced by a standard normal</span>
    <span class="n">hier_norm_lik</span> <span class="o">=</span> <span class="n">Y_tfp</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">y_T_reshaped</span><span class="p">)</span>
    <span class="c1"># Nothing should happen to this one</span>
    <span class="n">hier_norm_lik</span> <span class="o">+=</span> <span class="n">X_tfp</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x_tf</span><span class="p">)</span>
    <span class="c1"># The transform y -&gt; x + tau * y should be applied to this term</span>
    <span class="n">hier_norm_lik</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">squared_difference</span><span class="p">(</span><span class="n">y_tf</span> <span class="o">/</span> <span class="n">tau_tf</span><span class="p">,</span> <span class="n">x_tf</span> <span class="o">/</span> <span class="n">tau_tf</span><span class="p">)</span>

    <span class="n">hier_norm_lik</span> <span class="o">=</span> <span class="n">normalize_tf_graph</span><span class="p">(</span><span class="n">hier_norm_lik</span><span class="p">)</span>
</pre></div>
</div>
<p><span class="xref std std-ref">non-trivial-transform-test-graph-print</span> shows the form that
a graph representing a hierarchical normal-normal model will generally take
in TFP.</p>
<div class="highlight-python notranslate" id="non-trivial-transform-test-graph-print"><div class="highlight"><pre><span></span><span class="n">tf_dprint</span><span class="p">(</span><span class="n">hier_norm_lik</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Tensor(AddV2):0,    dtype=float32,  shape=[None],   &quot;add_1:0&quot;
|  Tensor(SquaredDifference):0,     dtype=float32,  shape=[None],   &quot;SquaredDifference:0&quot;
|  |  Tensor(RealDiv):0,    dtype=float32,  shape=[None],   &quot;Y_1/log_prob/truediv_1:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[None],   &quot;value_x:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  |  Tensor(RealDiv):0,    dtype=float32,  shape=[None],   &quot;truediv:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[None],   &quot;value_y:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  Tensor(AddV2):0, dtype=float32,  shape=[None],   &quot;add:0&quot;
|  |  Tensor(Sub):0,        dtype=float32,  shape=[None],   &quot;X_1/log_prob/sub:0&quot;
|  |  |  Tensor(Mul):0,     dtype=float32,  shape=[None],   &quot;X_1/log_prob/mul:0&quot;
|  |  |  |  Tensor(SquaredDifference):0,    dtype=float32,  shape=[None],   &quot;X_1/log_prob/SquaredDifference:0&quot;
|  |  |  |  |  Tensor(Mul):0,       dtype=float32,  shape=[None],   &quot;X_1/log_prob/truediv:0&quot;
|  |  |  |  |  |  Tensor(Const):0,  dtype=float32,  shape=[],       &quot;ConstantFolding/X_1/log_prob/truediv_recip:0&quot;
|  |  |  |  |  |  |  1.
|  |  |  |  |  |  Tensor(Placeholder):0,    dtype=float32,  shape=[None],   &quot;value_x:0&quot;
|  |  |  |  |  Tensor(Const):0,     dtype=float32,  shape=[],       &quot;X_1/log_prob/truediv_1:0&quot;
|  |  |  |  |  |  0.
|  |  |  |  Tensor(Const):0,        dtype=float32,  shape=[],       &quot;Y_1/log_prob/mul/x:0&quot;
|  |  |  |  |  -0.5
|  |  |  Tensor(Const):0,   dtype=float32,  shape=[],       &quot;Y_1/log_prob/add/x:0&quot;
|  |  |  |  0.9189385
|  |  Tensor(Sub):0,        dtype=float32,  shape=[None],   &quot;Y_1/log_prob/sub:0&quot;
|  |  |  Tensor(Mul):0,     dtype=float32,  shape=[None],   &quot;Y_1/log_prob/mul:0&quot;
|  |  |  |  Tensor(SquaredDifference):0,    dtype=float32,  shape=[None],   &quot;Y_1/log_prob/SquaredDifference:0&quot;
|  |  |  |  |  Tensor(RealDiv):0,   dtype=float32,  shape=[None],   &quot;Y_1/log_prob/truediv:0&quot;
|  |  |  |  |  |  Tensor(Reshape):0,        dtype=float32,  shape=[],       &quot;Reshape:0&quot;
|  |  |  |  |  |  |  Tensor(Placeholder):0, dtype=float32,  shape=[None],   &quot;value_y:0&quot;
|  |  |  |  |  |  |  Tensor(Const):0,       dtype=int32,    shape=[0],      &quot;Reshape/shape:0&quot;
|  |  |  |  |  |  |  |  []
|  |  |  |  |  |  Tensor(Placeholder):0,    dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  |  |  |  |  Tensor(RealDiv):0,   dtype=float32,  shape=[None],   &quot;Y_1/log_prob/truediv_1:0&quot;
|  |  |  |  |  |  ...
|  |  |  |  Tensor(Const):0,        dtype=float32,  shape=[],       &quot;Y_1/log_prob/mul/x:0&quot;
|  |  |  |  |  -0.5
|  |  |  Tensor(AddV2):0,   dtype=float32,  shape=[None],   &quot;Y_1/log_prob/add:0&quot;
|  |  |  |  Tensor(Log):0,  dtype=float32,  shape=[None],   &quot;Y_1/log_prob/Log:0&quot;
|  |  |  |  |  Tensor(Placeholder):0,       dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  |  |  |  Tensor(Const):0,        dtype=float32,  shape=[],       &quot;Y_1/log_prob/add/x:0&quot;
|  |  |  |  |  0.9189385
</pre></div>
</div>
<p><span class="xref std std-ref">non-trivial-transform-test-apply</span> runs our transformation and
<span class="xref std std-ref">non-trivial-transform-test-print-graph</span> prints the resulting graph.</p>
<div class="highlight-python notranslate" id="non-trivial-transform-test-apply"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">graph_mode</span><span class="p">(),</span> <span class="n">hier_norm_lik</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">test_output_res</span> <span class="o">=</span> <span class="n">shift_squared_terms</span><span class="p">(</span><span class="n">hier_norm_lik</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">test_output_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="non-trivial-transform-test-print-graph"><div class="highlight"><pre><span></span><span class="n">tf_dprint</span><span class="p">(</span><span class="n">test_output_res</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Tensor(AddV2):0,    dtype=float32,  shape=[None],   &quot;add_1_1:0&quot;
|  Tensor(SquaredDifference):0,     dtype=float32,  shape=[None],   &quot;SquaredDifference_5:0&quot;
|  |  Tensor(RealDiv):0,    dtype=float32,  shape=[None],   &quot;Y_1/log_prob/truediv_1:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[None],   &quot;value_x:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  |  Tensor(RealDiv):0,    dtype=float32,  shape=[None],   &quot;truediv_1:0&quot;
|  |  |  Tensor(AddV2):0,   dtype=float32,  shape=[None],   &quot;AddV2:0&quot;
|  |  |  |  Tensor(Mul):0,  dtype=float32,  shape=[None],   &quot;Mul_8:0&quot;
|  |  |  |  |  Tensor(Placeholder):0,       dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  |  |  |  |  Tensor(Placeholder):0,       dtype=float32,  shape=[None],   &quot;value_y:0&quot;
|  |  |  |  Tensor(Placeholder):0,  dtype=float32,  shape=[None],   &quot;value_x:0&quot;
|  |  |  Tensor(Placeholder):0,     dtype=float32,  shape=[None],   &quot;tau:0&quot;
|  Tensor(AddV2):0, dtype=float32,  shape=[None],   &quot;add_2:0&quot;
|  |  Tensor(Sub):0,        dtype=float32,  shape=[None],   &quot;X_1/log_prob/sub:0&quot;
|  |  |  Tensor(Mul):0,     dtype=float32,  shape=[None],   &quot;X_1/log_prob/mul:0&quot;
|  |  |  |  Tensor(SquaredDifference):0,    dtype=float32,  shape=[None],   &quot;X_1/log_prob/SquaredDifference:0&quot;
|  |  |  |  |  Tensor(Mul):0,       dtype=float32,  shape=[None],   &quot;X_1/log_prob/truediv:0&quot;
|  |  |  |  |  |  Tensor(Const):0,  dtype=float32,  shape=[],       &quot;ConstantFolding/X_1/log_prob/truediv_recip:0&quot;
|  |  |  |  |  |  |  1.
|  |  |  |  |  |  Tensor(Placeholder):0,    dtype=float32,  shape=[None],   &quot;value_x:0&quot;
|  |  |  |  |  Tensor(Const):0,     dtype=float32,  shape=[],       &quot;X_1/log_prob/truediv_1:0&quot;
|  |  |  |  |  |  0.
|  |  |  |  Tensor(Const):0,        dtype=float32,  shape=[],       &quot;Y_1/log_prob/mul/x:0&quot;
|  |  |  |  |  -0.5
|  |  |  Tensor(Const):0,   dtype=float32,  shape=[],       &quot;Y_1/log_prob/add/x:0&quot;
|  |  |  |  0.9189385
|  |  Tensor(Sub):0,        dtype=float32,  shape=[],       &quot;sub_1_1:0&quot;
|  |  |  Tensor(Mul):0,     dtype=float32,  shape=[],       &quot;mul_3_1:0&quot;
|  |  |  |  Tensor(SquaredDifference):0,    dtype=float32,  shape=[],       &quot;SquaredDifference_2_1:0&quot;
|  |  |  |  |  Tensor(Reshape):0,   dtype=float32,  shape=[],       &quot;Reshape_1:0&quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    dtype=float32,  shape=[None],   &quot;value_y:0&quot;
|  |  |  |  |  |  Tensor(Const):0,  dtype=int32,    shape=[0],      &quot;Reshape/shape:0&quot;
|  |  |  |  |  |  |  []
|  |  |  |  |  Tensor(Const):0,     dtype=float32,  shape=[],       &quot;X_1/log_prob/truediv_1:0&quot;
|  |  |  |  |  |  0.
|  |  |  |  Tensor(Const):0,        dtype=float32,  shape=[],       &quot;Y_1/log_prob/mul/x:0&quot;
|  |  |  |  |  -0.5
|  |  |  Tensor(Const):0,   dtype=float32,  shape=[],       &quot;Y_1/log_prob/add/x:0&quot;
|  |  |  |  0.9189385
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="transforming-the-log-likelihood-graph">
<h2>Transforming the Log-likelihood Graph<a class="headerlink" href="#transforming-the-log-likelihood-graph" title="Permalink to this headline">¶</a></h2>
<p>Now, we’re ready to apply the transform to the radon model log-likelihood graph.</p>
<div class="highlight-python notranslate" id="transform-logpfn"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">graph_mode</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">trans_graph</span><span class="p">:</span>

    <span class="n">logpfn_fg_out</span> <span class="o">=</span> <span class="n">normalize_tf_graph</span><span class="p">(</span><span class="n">logpfn_fg</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">logpfn_trans_tf</span> <span class="o">=</span> <span class="n">shift_squared_terms</span><span class="p">(</span><span class="n">logpfn_fg_out</span><span class="p">)</span>

<span class="k">with</span> <span class="n">graph_mode</span><span class="p">(),</span> <span class="n">logpfn_fg_out</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">out_graph_lv</span> <span class="o">=</span> <span class="n">var</span><span class="p">()</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_graph_lv</span><span class="p">,</span> <span class="n">reduceo</span><span class="p">(</span><span class="n">shift_squared_subso</span><span class="p">,</span> <span class="n">logpfn_fg_out</span><span class="p">,</span> <span class="n">out_graph_lv</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reify</span><span class="p">()</span>

    <span class="c1"># FIXME: commutative eq is causing us to reify ground/base sub-graphs with the wrong</span>
    <span class="c1"># parameter order.</span>
    <span class="kn">from</span> <span class="nn">symbolic_pymc.utils</span> <span class="kn">import</span> <span class="n">meta_parts_unequal</span>
    <span class="n">meta_parts_unequal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mt</span><span class="p">(</span><span class="n">existing_op</span><span class="p">))</span>

<span class="k">assert</span> <span class="n">logpfn_trans_tf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="simplify-transformed-logpfn"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">graph_mode</span><span class="p">(),</span> <span class="n">logpfn_trans_tf</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">var</span><span class="p">(</span><span class="s1">&#39;q&#39;</span><span class="p">),</span>
              <span class="n">reduceo</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">walko</span><span class="p">(</span><span class="n">recenter_sqrdiffo</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
                      <span class="n">logpfn_trans_tf</span><span class="p">,</span> <span class="n">var</span><span class="p">(</span><span class="s1">&#39;q&#39;</span><span class="p">)))</span>

    <span class="n">logpfn_trans_tf</span> <span class="o">=</span> <span class="n">normalize_tf_graph</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">eval_obj</span><span class="o">.</span><span class="n">reify</span><span class="p">())</span>
</pre></div>
</div>
<p><span class="xref std std-ref">print-transformed-remaps</span> shows the replacements that were made
throughout the graph.  Two replacements were found and they appear to correspond
to the un-centered normal distribution terms <code class="docutils literal notranslate"><span class="pre">a</span></code>and <code class="docutils literal notranslate"><span class="pre">b</span></code> in our model–as intended.</p>
<div class="highlight-python notranslate" id="print-transformed-remaps"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">rm</span> <span class="ow">in</span> <span class="n">logpfn_remaps</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">rm</span><span class="p">:</span>
      <span class="n">tf_dprint</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&gt;&quot;</span><span class="p">)</span>
      <span class="n">tf_dprint</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Tensor(Placeholder):0,      shape=[85]      &quot;values_2:0&quot;
-&gt;
Tensor(AddV2):0,    shape=[85]      &quot;AddV2:0&quot;
|  Tensor(Placeholder):0,   shape=[]        &quot;values_4:0&quot;
|  Tensor(Mul):0,   shape=[85]      &quot;Mul_4:0&quot;
|  |  Tensor(Exp):0,        shape=[]        &quot;exp_2_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0,     shape=[]        &quot;values_5:0&quot;
|  |  Tensor(Placeholder):0,        shape=[85]      &quot;values_2:0&quot;
------
Tensor(Log):0,      shape=~_175065  &quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/Log:0&quot;
|  Tensor(Exp):0,   shape=[]        &quot;exp_2_1/forward/Exp:0&quot;
|  |  Tensor(Placeholder):0,        shape=[]        &quot;values_5:0&quot;
-&gt;
0.0
------
</pre></div>
</div>
<p>Likewise, <span class="xref std std-ref">show-squared-diff-terms-in-trans</span> shows
<code class="docutils literal notranslate"><span class="pre">SquaredDifference</span></code> subgraphs that appear in the
transformed log-likelihood.</p>
<div class="highlight-python notranslate" id="show-squared-diff-terms-in-trans"><div class="highlight"><pre><span></span><span class="n">square_diff_outs</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">logpfn_trans_tf</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_operations</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">o</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;SquaredDifference&#39;</span> <span class="ow">or</span>
                    <span class="n">o</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;Gather&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">o</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;Log&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">square_diff_outs</span><span class="p">:</span>
    <span class="n">tf_dprint</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Tensor(GatherV2):0, shape=[919]     &quot;GatherV2:0&quot;
|  Tensor(Placeholder):0,   shape=[85]      &quot;values_3:0&quot;
|  Tensor(Const):0, shape=[919]     &quot;GatherV2/indices:0&quot;
|  |  [ 0  0  0 ... 83 84 84]
|  Tensor(Const):0, shape=[]        &quot;GatherV2/axis:0&quot;
|  |  0
Tensor(Log):0,      shape=[]        &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/Log:0&quot;
|  Tensor(Exp):0,   shape=[]        &quot;exp_1/forward/Exp:0&quot;
|  |  Tensor(Placeholder):0,        shape=[]        &quot;values_0:0&quot;
Tensor(SquaredDifference):0,        shape=[]        &quot;Normal_5/log_prob/SquaredDifference:0&quot;
|  Tensor(Const):0, shape=[]        &quot;Const_723:0&quot;
|  |  0.
|  Tensor(Mul):0,   shape=[]        &quot;Normal_5/log_prob/truediv:0&quot;
|  |  Tensor(Const):0,      shape=[]        &quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&quot;
|  |  |  1.
|  |  Tensor(Placeholder):0,        shape=[]        &quot;values_1:0&quot;
Tensor(SquaredDifference):0,        shape=[85]      &quot;SquaredDifference:0&quot;
|  Tensor(Const):0, shape=[]        &quot;Const_723:0&quot;
|  |  0.
|  Tensor(Reshape):0,       shape=[85]      &quot;Reshape:0&quot;
|  |  Tensor(Placeholder):0,        shape=[85]      &quot;values_2:0&quot;
|  |  Tensor(Const):0,      shape=[1]       &quot;SampleNormal_2_1/log_prob/Reshape/shape:0&quot;
|  |  |  [85]
Tensor(SquaredDifference):0,        shape=[]        &quot;Normal_1_1/log_prob/SquaredDifference:0&quot;
|  Tensor(Const):0, shape=[]        &quot;Const_723:0&quot;
|  |  0.
|  Tensor(Mul):0,   shape=[]        &quot;Normal_1_1/log_prob/truediv:0&quot;
|  |  Tensor(Const):0,      shape=[]        &quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&quot;
|  |  |  1.
|  |  Tensor(Placeholder):0,        shape=[]        &quot;values_4:0&quot;
Tensor(Log):0,      shape=[]        &quot;Normal_4_1/log_prob/Log:0&quot;
|  Tensor(Exp):0,   shape=[]        &quot;exp_3_1/forward/Exp:0&quot;
|  |  Tensor(Placeholder):0,        shape=[]        &quot;values_6:0&quot;
Tensor(SquaredDifference):0,        shape=[85]      &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,       shape=[85]      &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv:0&quot;
|  |  Tensor(Reshape):0,    shape=[85]      &quot;SampleNormal_2_1/log_prob/Reshape:0&quot;
|  |  |  Tensor(Placeholder):0,     shape=[85]      &quot;values_3:0&quot;
|  |  |  Tensor(Const):0,   shape=[1]       &quot;SampleNormal_2_1/log_prob/Reshape/shape:0&quot;
|  |  |  |  [85]
|  |  Tensor(Exp):0,        shape=[]        &quot;exp_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0,     shape=[]        &quot;values_0:0&quot;
|  Tensor(RealDiv):0,       shape=[]        &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv_1:0&quot;
|  |  Tensor(Placeholder):0,        shape=[]        &quot;values_1:0&quot;
|  |  Tensor(Exp):0,        shape=[]        &quot;exp_1/forward/Exp:0&quot;
|  |  |  ...
Tensor(GatherV2):0, shape=[919]     &quot;GatherV2_1_1:0&quot;
|  Tensor(AddV2):0, shape=[85]      &quot;AddV2:0&quot;
|  |  Tensor(Mul):0,        shape=[85]      &quot;Mul_4:0&quot;
|  |  |  Tensor(Exp):0,     shape=[]        &quot;exp_2_1/forward/Exp:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[]        &quot;values_5:0&quot;
|  |  |  Tensor(Placeholder):0,     shape=[85]      &quot;values_2:0&quot;
|  |  Tensor(Placeholder):0,        shape=[]        &quot;values_4:0&quot;
|  Tensor(Const):0, shape=[919]     &quot;GatherV2/indices:0&quot;
|  |  [ 0  0  0 ... 83 84 84]
|  Tensor(Const):0, shape=[]        &quot;GatherV2/axis:0&quot;
|  |  0
Tensor(SquaredDifference):0,        shape=[919]     &quot;Normal_4_1/log_prob/SquaredDifference_1:0&quot;
|  Tensor(RealDiv):0,       shape=[919]     &quot;Normal_4_1/log_prob/truediv:0&quot;
|  |  Tensor(Const):0,      shape=[919]     &quot;Normal_4_1/log_prob/value:0&quot;
|  |  |  [0.8329091 0.8329091 1.0986123 ... 1.6292405 1.3350011 1.0986123]
|  |  Tensor(Exp):0,        shape=[]        &quot;exp_3_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0,     shape=[]        &quot;values_6:0&quot;
|  Tensor(RealDiv):0,       shape=[919]     &quot;Normal_4_1/log_prob/truediv_1_1:0&quot;
|  |  Tensor(AddV2):0,      shape=[919]     &quot;add_12:0&quot;
|  |  |  Tensor(GatherV2):0,        shape=[919]     &quot;GatherV2:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[85]      &quot;values_3:0&quot;
|  |  |  |  Tensor(Const):0,        shape=[919]     &quot;GatherV2/indices:0&quot;
|  |  |  |  |  [ 0  0  0 ... 83 84 84]
|  |  |  |  Tensor(Const):0,        shape=[]        &quot;GatherV2/axis:0&quot;
|  |  |  |  |  0
|  |  |  Tensor(Mul):0,     shape=[919]     &quot;mul_5:0&quot;
|  |  |  |  Tensor(GatherV2):0,     shape=[919]     &quot;GatherV2_1_1:0&quot;
|  |  |  |  |  Tensor(AddV2):0,     shape=[85]      &quot;AddV2:0&quot;
|  |  |  |  |  |  Tensor(Mul):0,    shape=[85]      &quot;Mul_4:0&quot;
|  |  |  |  |  |  |  Tensor(Exp):0, shape=[]        &quot;exp_2_1/forward/Exp:0&quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,      shape=[]        &quot;values_5:0&quot;
|  |  |  |  |  |  |  Tensor(Placeholder):0, shape=[85]      &quot;values_2:0&quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[]        &quot;values_4:0&quot;
|  |  |  |  |  Tensor(Const):0,     shape=[919]     &quot;GatherV2/indices:0&quot;
|  |  |  |  |  |  [ 0  0  0 ... 83 84 84]
|  |  |  |  |  Tensor(Const):0,     shape=[]        &quot;GatherV2/axis:0&quot;
|  |  |  |  |  |  0
|  |  |  |  Tensor(Const):0,        shape=[919]     &quot;mul/y:0&quot;
|  |  |  |  |  [1. 0. 0. ... 0. 0. 0.]
|  |  Tensor(Exp):0,        shape=[]        &quot;exp_3_1/forward/Exp:0&quot;
|  |  |  ...
</pre></div>
</div>
</div>
<div class="section" id="creating-a-new-log-likelihood-function">
<h2>Creating a new Log-likelihood Function<a class="headerlink" href="#creating-a-new-log-likelihood-function" title="Permalink to this headline">¶</a></h2>
<p>Now that we have a transformed version of the original log-likelihood graph
(i.e. <code class="docutils literal notranslate"><span class="pre">logpfn_trans_tf</span></code>), we need to create a
new <code class="docutils literal notranslate"><span class="pre">FuncGraph</span></code> from it.  <span class="xref std std-ref">create-new-func-graph</span>
provides a simple function that creates a
new <code class="docutils literal notranslate"><span class="pre">ConcreteFunction</span></code> from an updated output node.</p>
<div class="highlight-python notranslate" id="new-tf-function"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.python.framework.func_graph</span> <span class="kn">import</span> <span class="n">FuncGraph</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager.function</span> <span class="kn">import</span> <span class="n">ConcreteFunction</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager.lift_to_graph</span> <span class="kn">import</span> <span class="n">lift_to_graph</span>


<span class="k">def</span> <span class="nf">new_tf_function</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">orig_cf</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a new ConcreteFunction by replacing a single output in an existing FuncGraph.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">orig_fg</span> <span class="o">=</span> <span class="n">orig_cf</span><span class="o">.</span><span class="n">graph</span>
    <span class="c1"># with trans_graph.as_default(): #orig_fg.as_default():</span>

    <span class="n">logpfn_fg_new</span> <span class="o">=</span> <span class="n">FuncGraph</span><span class="p">(</span><span class="s1">&#39;logpfn_new&#39;</span><span class="p">,</span> <span class="n">orig_fg</span><span class="o">.</span><span class="n">collections</span><span class="p">,</span> <span class="n">orig_fg</span><span class="o">.</span><span class="n">capture_by_value</span><span class="p">)</span>

    <span class="n">old_to_new_ops</span> <span class="o">=</span> <span class="n">lift_to_graph</span><span class="p">([</span><span class="n">output</span><span class="p">],</span>
                                    <span class="n">logpfn_fg_new</span><span class="p">,</span>
                                    <span class="n">add_sources</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                    <span class="n">handle_captures</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">logpfn_fg_new</span><span class="o">.</span><span class="n">structured_input_signature</span> <span class="o">=</span> <span class="n">orig_fg</span><span class="o">.</span><span class="n">structured_input_signature</span>

    <span class="n">new_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">old_to_new_ops</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_operation_by_name</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">name</span><span class="p">)</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">orig_cf</span><span class="o">.</span><span class="n">structured_input_signature</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

    <span class="n">logpfn_fg_new</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">new_inputs</span>

    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">i</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">logpfn_fg_new</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>

    <span class="n">logpfn_fg_new</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">old_to_new_ops</span><span class="p">[</span><span class="n">output</span><span class="p">]]</span>
    <span class="n">logpfn_fg_new</span><span class="o">.</span><span class="n">structured_outputs</span> <span class="o">=</span> <span class="n">logpfn_fg_new</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">assert</span> <span class="n">logpfn_fg_new</span><span class="o">.</span><span class="n">as_graph_element</span><span class="p">(</span><span class="n">logpfn_fg_new</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="n">logpfn_new_cf</span> <span class="o">=</span> <span class="n">ConcreteFunction</span><span class="p">(</span><span class="n">logpfn_fg_new</span><span class="p">)</span>
    <span class="n">logpfn_new_cf</span><span class="o">.</span><span class="n">_arg_keywords</span> <span class="o">=</span> <span class="n">orig_cf</span><span class="o">.</span><span class="n">_arg_keywords</span>
    <span class="n">logpfn_new_cf</span><span class="o">.</span><span class="n">_num_positional_args</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">logpfn_fg_new</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">logpfn_new_cf</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="create-new-func-graph"><div class="highlight"><pre><span></span><span class="n">logpfn_new_cf</span> <span class="o">=</span> <span class="n">new_tf_function</span><span class="p">(</span><span class="n">logpfn_trans_tf</span><span class="p">,</span> <span class="n">logpfn_cf</span><span class="p">)</span>
</pre></div>
</div>
<p>The new TF function, <code class="docutils literal notranslate"><span class="pre">logpfn_new_cf</span></code>, in
<span class="xref std std-ref">create-new-func-graph</span> is the function we are going to use for sampling
from the new log-likelihood.</p>
<div class="highlight-python notranslate" id="demo-diff-fgraph-output"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">logpfn_cf</span><span class="p">(</span><span class="o">*</span><span class="n">init</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">-</span> <span class="n">logpfn_new_cf</span><span class="p">(</span><span class="o">*</span><span class="n">init</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mf">153.41016</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p><span class="xref std std-ref">demo-diff-fgraph-output</span> shows the difference between a transformed and
non-transformed log-likelihood value given the same inputs.</p>
</div>
<div class="section" id="sampling-from-the-new-log-likelihood">
<h2>Sampling from the new Log-likelihood<a class="headerlink" href="#sampling-from-the-new-log-likelihood" title="Permalink to this headline">¶</a></h2>
<p>In <span class="xref std std-ref">sample-transformed-model</span>, we reproduce the remaining steps
of <code class="docutils literal notranslate"><span class="pre">pm.inference.sampling.sample</span></code> and–unnaturally–force
the PyMC4 machinery to draw samples from our new transformed log-likelihood
function.</p>
<div class="highlight-python notranslate" id="hijack-build-logp"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">contextmanager</span>


<span class="c1"># We need to create new initial values for our transformed variables.</span>
<span class="n">new_val_map</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">logpfn_remap</span> <span class="ow">in</span> <span class="n">logpfn_remaps</span><span class="p">:</span>
    <span class="n">transed_var</span> <span class="o">=</span> <span class="n">logpfn_remap</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reify</span><span class="p">()</span>
    <span class="n">transed_var_pymc_name</span> <span class="o">=</span> <span class="n">tfp_names_to_pymc</span><span class="p">[</span><span class="n">transed_var</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
    <span class="n">old_val_np</span> <span class="o">=</span> <span class="n">init</span><span class="p">[</span><span class="n">transed_var_pymc_name</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">new_val_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">old_val_np</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">old_val_np</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">new_val_map</span><span class="p">[</span><span class="n">transed_var_pymc_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">new_val_np</span><span class="p">)</span>

<span class="n">new_init</span> <span class="o">=</span> <span class="n">init</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">new_init</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">new_val_map</span><span class="p">)</span>


<span class="nd">@contextmanager</span>
<span class="k">def</span> <span class="nf">pymc4_force_logp</span><span class="p">(</span><span class="n">logpfn_new_cf</span><span class="p">,</span> <span class="n">new_init</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Temporarily fix the logp function and init values used by PyMC4&#39;s sampler.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_new_build_logp_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">nonlocal</span> <span class="n">logpfn_new_cf</span><span class="p">,</span> <span class="n">new_init</span>
        <span class="k">return</span> <span class="n">logpfn_new_cf</span><span class="p">,</span> <span class="n">new_init</span>

    <span class="n">_old_fn</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">inference</span><span class="o">.</span><span class="n">sampling</span><span class="o">.</span><span class="n">build_logp_function</span>
    <span class="n">pm</span><span class="o">.</span><span class="n">inference</span><span class="o">.</span><span class="n">sampling</span><span class="o">.</span><span class="n">build_logp_function</span> <span class="o">=</span> <span class="n">_new_build_logp_function</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">pm</span><span class="o">.</span><span class="n">inference</span><span class="o">.</span><span class="n">sampling</span><span class="o">.</span><span class="n">build_logp_function</span> <span class="o">=</span> <span class="n">_old_fn</span>
</pre></div>
</div>
<div class="highlight-python notranslate" id="sample-transformed-model"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pymc4_force_logp</span><span class="p">(</span><span class="n">logpfn_new_cf</span><span class="p">,</span> <span class="n">new_init</span><span class="p">):</span>
    <span class="n">az_trace</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<div class="align-center figure" id="id4">
<span id="fig-transformed-model-plot-energy"></span><a class="reference internal image-reference" href="_images/transformed-model-plot-energy.png"><img alt="_images/transformed-model-plot-energy.png" src="_images/transformed-model-plot-energy.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-number">Fig. 5 </span><span class="caption-text">Post-transform MCMC energy</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<div class="align-center figure" id="id5">
<span id="fig-transformed-model-plot-trace"></span><a class="reference internal image-reference" href="_images/transformed-model-plot-trace.png"><img alt="_images/transformed-model-plot-trace.png" src="_images/transformed-model-plot-trace.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-number">Fig. 6 </span><span class="caption-text">Post-transform MCMC trace</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="discussion">
<h2>Discussion<a class="headerlink" href="#discussion" title="Permalink to this headline">¶</a></h2>
<p>The goals in the two separate <code class="docutils literal notranslate"><span class="pre">run</span></code> calls we used in
<span class="xref std std-ref">kanren-shift-squaredo-func</span> could have been combined into a
single <code class="docutils literal notranslate"><span class="pre">run</span></code>.  This could’ve been accomplished using some
“meta” steps (e.g. construct and evaluate a goal on-the-fly within a
miniKanren) or special goals for reading from a
miniKanren-generated <code class="docutils literal notranslate"><span class="pre">dict</span></code>s or association lists.
Goals of this nature are not uncommon (e.g. type inference and inhabitation exmaples),
and serve to demonstrate the great breadth of activity possible within relational
context of miniKanren.</p>
<p>However, the point we want to make doesn’t require much sophistication.
Instead, we wanted to demonstrate how a non-trivial “pattern” can be specified
and matched using <code class="docutils literal notranslate"><span class="pre">symbolic-pymc</span></code>, and how easily those results
could be used to transform a graph.</p>
<p>More specifically, our goal <code class="docutils literal notranslate"><span class="pre">shift_squared_subso</span></code> in
<span class="xref std std-ref">kanren-shift-squaredo-func</span> demonstrates <strong>the way in which we were able to specify desired structure(s) within a graph</strong>.
We defined one pattern, <code class="docutils literal notranslate"><span class="pre">Y_sqrdiffo</span></code>, to match anywhere
in the graph then another pattern, <code class="docutils literal notranslate"><span class="pre">X_sqrdiffo</span></code>, that
relied on matched terms from <code class="docutils literal notranslate"><span class="pre">Y_sqrdiffo</span></code> and could also
be matched/found anywhere else in the same graph.</p>
<p>Furthermore, our substitutions needed information from both “matched” subgraphs.
Specifically, substitution pairs similar
to <code class="docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">z</span> <span class="pre">+</span> <span class="pre">x)</span></code>.  Within this framework, we could just as
easily have included <code class="docutils literal notranslate"><span class="pre">y</span></code>–or any terms from either
successfully matched subgraph–in the substitution expressions.</p>
<p>In sample-space, the search patterns and substitutions are much easier to specify exactly
because they’re single-subgraph patterns that themselves are the subgraphs to be replaced
(i.e. if we find a non-standard normal, replace it with a shifted/scaled standard normal).
In log-space, we chose to find distinct subgraph “chains”,
i.e. all <code class="docutils literal notranslate"><span class="pre">(y</span> <span class="pre">-</span> <span class="pre">x)**2</span></code>and <code class="docutils literal notranslate"><span class="pre">(x</span> <span class="pre">-</span> <span class="pre">z)**2</span></code> pairs (i.e. “connected” by an “unknown”
term <code class="docutils literal notranslate"><span class="pre">x</span></code>), since these are produced by the log-likelihood form of
hierarchical normal distributions.</p>
<p>As a result, we had a non-trivial structure/”pattern” to express–and execute.  Using
conventional graph search-and-replace functionality would’ve required much more orchestration
and resulted considerably less flexible code with little-to-no reusability.
In our case, the goals <code class="docutils literal notranslate"><span class="pre">onceo</span></code> and <code class="docutils literal notranslate"><span class="pre">walko</span></code>are universal and the forms in <code class="docutils literal notranslate"><span class="pre">shift_squared_subso</span></code> can be easily
changed to account for more sophisticated (or entirely distinct) patterns and substitutions.</p>
<p>Most related graph manipulation offerings make it easy to find a single subgraph that
matches a pattern, but not potentially “co-dependent” and/or distinct subgraphs.
In the end, the developer will often have to manually implement a “global” state
and orchestrate multiple single-subgraph searches and their results.</p>
<p>For single search-and-replace objectives, this amount of manual developer
intervention/orchestration might be excusable; however, for objectives requiring
the evaluation of multiple graph transformation, this approach is mostly
unmaintainable and extremely difficult to compartmentalize.</p>
<p>This demonstration barely even scratches the surface of what’s possible
using miniKanren and relational programming for graph manipulation and
symbolic statistical model optimization.  As the <code class="docutils literal notranslate"><span class="pre">symbolic-pymc</span></code>project advances, we’ll cover examples in which miniKanren’s more distinct
offerings are demonstrated.</p>
</div>
</div>


    </div>
</div>
<div class="ui vertical footer segment">
    <div class="ui center aligned container">
        <a href="https://github.com/pymc-devs/symbolic-pymc"><i class="github icon large"></i></a>
        <a href="https://twitter.com/pymc_devs"><i class="twitter icon large"></i></a>
        <a href="https://discourse.pymc.io/"><i class="discourse icon large"></i></a>
    </div>
    <div class="ui center aligned container">
        <p>
            &copy; Copyright 2019, PyMC developers.
        </p>
        <p>
            Created using <a href="https://sphinx-doc.org/">Sphinx</a> 2.4.3.<br />
        </p>
    </div>
</div>
  </body>
</html>